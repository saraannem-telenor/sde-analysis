{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for fetching real data is that CERRA data is quite similar among units and different from Statkraft. Double check with real data whether there are no bugs in getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pyproj import CRS, Transformer\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "import dask\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "shp_file = \"data/raw/catchment_statkraft/catchment.shp\"\n",
    "catchment = gpd.read_file(shp_file)\n",
    "# Check the coordinate reference system (CRS)\n",
    "print(catchment.crs)\n",
    "# Plot the shapefile\n",
    "catchment.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "shp_file_norway = \"data/raw/other_data/norwayshapefiles/Kommune_FLATE.shp\"\n",
    "catchment_norway = gpd.read_file(shp_file_norway)\n",
    "catchment_norway.columns = catchment_norway.columns.str.lower()\n",
    "catchment_norway.columns = catchment_norway.columns.str.strip()\n",
    "# Check the coordinate reference system (CRS)\n",
    "print(catchment_norway.crs)\n",
    "# Plot the shapefile\n",
    "catchment_norway.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 14))\n",
    "\n",
    "# Plot all catchments in Norway with different colors\n",
    "catchment_norway.plot(\n",
    "    ax=ax,\n",
    "    categorical=True,\n",
    "    cmap=\"tab20\",  # colorful and clear for categories\n",
    "    legend=False,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.5,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Plot the specific catchment with thick red border\n",
    "catchment.boundary.plot(ax=ax, edgecolor=\"red\", linewidth=2, label=\"Target Catchment\")\n",
    "\n",
    "\n",
    "# Final touches\n",
    "ax.set_title(\"Norway Catchments with Highlighted Target Catchment\", fontsize=16)\n",
    "ax.set_axis_off()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "name = \"navn\"\n",
    "# Plot all Norway catchments with colors\n",
    "catchment_norway.plot(\n",
    "    ax=ax,\n",
    "    column=name if name in catchment_norway.columns else None,\n",
    "    categorical=True,\n",
    "    cmap=\"tab20\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.5,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Overlay your catchment with a red border\n",
    "catchment.boundary.plot(ax=ax, edgecolor=\"red\", linewidth=2, label=\"Target Catchment\")\n",
    "\n",
    "# Zoom to the catchment\n",
    "minx, miny, maxx, maxy = catchment.total_bounds\n",
    "pad_x = (maxx - minx) * 0.05\n",
    "pad_y = (maxy - miny) * 0.05\n",
    "ax.set_xlim(minx - pad_x, maxx + pad_x)\n",
    "ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "\n",
    "# Label only nearby regions (that intersect the catchment)\n",
    "nearby_regions = catchment_norway[catchment_norway.intersects(catchment.union_all())]\n",
    "\n",
    "if name in nearby_regions.columns:\n",
    "    for idx, row in nearby_regions.iterrows():\n",
    "        label_point = row.geometry.intersection(catchment.union_all()).centroid\n",
    "        ax.text(label_point.x, label_point.y, str(row[name]), fontsize=9, ha='center', color=\"black\")\n",
    "\n",
    "# Title, formatting\n",
    "ax.set_title(\"Zoomed-In Catchment Area with Nearby Region Labels\", fontsize=14)\n",
    "ax.set_axis_off()\n",
    "plt.legend()\n",
    "plt.tight_layout();\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data is provided per year: preprocessing and concatenating\n",
    "#### Skip if real data is already fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder containing the NetCDF files\n",
    "folder_path = \"data/raw/other_data/sde\"\n",
    "\n",
    "# List all NetCDF files in the folder\n",
    "nc_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.nc')]\n",
    "\n",
    "ds_list = []\n",
    "for nc_file in nc_files:\n",
    "    # Load the NetCDF file\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    # Print the dataset\n",
    "    ds_list.append(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check if all values in the snow_depth variable are NaN\n",
    "def check_all_nan(nc_file):\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    if 'snow_depth' in ds:\n",
    "        all_nan = ds['snow_depth'].isnull().all()\n",
    "        return all_nan.item()  # Convert to a Python boolean\n",
    "    else:\n",
    "        print(f\"No snow_depth variable found in {nc_file}\")\n",
    "        return None\n",
    "\n",
    "# Check each NetCDF file for NaN values in the snow_depth variable\n",
    "for nc_file in nc_files:\n",
    "    all_nan = check_all_nan(nc_file)\n",
    "    if all_nan is not None:\n",
    "        if all_nan:\n",
    "            print(f\"All values in snow_depth are NaN in {nc_file}\")\n",
    "        else:\n",
    "            print(f\"Not all values in snow_depth are NaN in {nc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the aggregated datasets along the time dimension\n",
    "ds_daily_concat = xr.concat(ds_list, dim='time')\n",
    "# Sort time values, just in case they're out of order\n",
    "ds_all = ds_daily_concat.sortby('time')\n",
    "ds_all.to_netcdf(\"snow_depth_concatenated.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch real data .nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = xr.open_dataset(\"data/raw/snow_depth_concatenated.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract proj4 string from the dataset\n",
    "proj4_str = ds_all['UTM_Zone_33'].attrs['proj4']\n",
    "netcdf_crs = CRS.from_proj4(proj4_str)\n",
    "\n",
    "print(\"Extracted CRS from NetCDF:\", netcdf_crs)\n",
    "# Reproject to NetCDF CRS\n",
    "catchments_proj = catchment.to_crs(netcdf_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select time slice (e.g., first time step)\n",
    "ds_all.sel(time='2015-01-01')['snow_depth'].plot(figsize = (18,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "sde = ds_all['snow_depth'].isel(time=-1)  # First time step\n",
    "x = ds_all['x'].values  # X-coordinates (projected)\n",
    "y = ds_all['y'].values  # Y-coordinates (projected)\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ”¹ Fix Grid Cell Alignment by Creating an Edged Grid\n",
    "X, Y = np.meshgrid(\n",
    "    np.linspace(x.min(), x.max(), sde.shape[1] + 1),  # X should be 1 larger than sde.shape[1]\n",
    "    np.linspace(y.min(), y.max(), sde.shape[0] + 1)   # Y should be 1 larger than sde.shape[0]\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Plot the Data Using pcolormesh()\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "c = ax.pcolormesh(X, Y, sde.values, cmap=\"viridis\", shading=\"flat\")  # Corrected!\n",
    "\n",
    "# Add a Colorbar\n",
    "cb = plt.colorbar(c, ax=ax)\n",
    "cb.set_label(\"Snow Depth (cm)\")\n",
    "\n",
    "# Overlay Catchment Shapefile (Correctly Reprojected)\n",
    "catchment.boundary.plot(ax=ax, edgecolor=\"red\", linewidth=2, label=\"Catchment Boundary\")\n",
    "\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel(\"X Coordinate (meters)\")\n",
    "ax.set_ylabel(\"Y Coordinate (meters)\")\n",
    "ax.set_title(\"Corrected Snow Depth Map with Catchment Overlay\")\n",
    "ax.set_aspect('equal')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zooming in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "\n",
    "padding = 0.3\n",
    "sde = ds_all['snow_depth'].isel(time=-1)  # First time step\n",
    "x = ds_all['x'].values  # X-coordinates (projected)\n",
    "y = ds_all['y'].values  # Y-coordinates (projected)\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ”¹ Fix Grid Cell Alignment by Creating an Edged Grid\n",
    "X, Y = np.meshgrid(\n",
    "    np.linspace(x.min(), x.max(), sde.shape[1] + 1),  # X should be 1 larger than sde.shape[1]\n",
    "    np.linspace(y.min(), y.max(), sde.shape[0] + 1)   # Y should be 1 larger than sde.shape[0]\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Plot the Data Using pcolormesh()\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "c = ax.pcolormesh(X, Y, sde.values, cmap=\"viridis\", shading=\"flat\")  # Corrected!\n",
    "\n",
    "# Add a Colorbar\n",
    "cb = plt.colorbar(c, ax=ax)\n",
    "cb.set_label(\"Snow Depth (cm)\")\n",
    "\n",
    "# Overlay Catchment Shapefile (Correctly Reprojected)\n",
    "catchment.boundary.plot(ax=ax, edgecolor=\"red\", linewidth=2, label=\"Catchment Boundary\")\n",
    "\n",
    "# Get bounding box from catchment\n",
    "minx, miny, maxx, maxy = catchment.total_bounds\n",
    "\n",
    "# Optional padding to avoid clipping\n",
    "pad_x = (maxx - minx) * padding  # 10% padding\n",
    "pad_y = (maxy - miny) * padding\n",
    "\n",
    "# Zoom to catchment extent\n",
    "ax.set_xlim(minx - pad_x, maxx + pad_x)\n",
    "ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel(\"X Coordinate (meters)\")\n",
    "ax.set_ylabel(\"Y Coordinate (meters)\")\n",
    "ax.set_title(\"Corrected Snow Depth Map with Catchment Overlay\")\n",
    "ax.set_aspect('equal')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerra_df = pd.read_csv(\"cerra_snow_depth_ordered.csv\")\n",
    "cerra_df.sort_values(by=['latitude', 'longitude'], inplace=True)\n",
    "# Get unique latitude and longitude pairs\n",
    "coords_df = cerra_df[['latitude', 'longitude']].drop_duplicates()\n",
    "coords_df.rename(columns={'latitude': 'lat', 'longitude': 'lon'}, inplace=True)\n",
    "\n",
    "# Display the unique latitude and longitude pairs\n",
    "print(\"Unique latitude and longitude pairs:\")\n",
    "print(coords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerra_df = pd.read_csv(\"data/processed/cerra_processed.csv\")\n",
    "# Get unique latitude and longitude pairs\n",
    "coords_df = cerra_df[['latitude', 'longitude']].drop_duplicates()\n",
    "coords_df.rename(columns={'latitude': 'lat', 'longitude': 'lon'}, inplace=True)\n",
    "\n",
    "# Display the unique latitude and longitude pairs\n",
    "print(\"Unique latitude and longitude pairs:\")\n",
    "print(coords_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ds = ds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a geodataframe from real_ds with latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Extract lat/lon and flatten\n",
    "lat_vals = real_ds['lat'].values\n",
    "lon_vals = real_ds['lon'].values\n",
    "snow_vals = real_ds['snow_depth'].isel(time=0).values  # just time=0 for now\n",
    "\n",
    "# Flatten arrays\n",
    "lat_flat = lat_vals.ravel()\n",
    "lon_flat = lon_vals.ravel()\n",
    "snow_flat = snow_vals.ravel()\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_real = gpd.GeoDataFrame({\n",
    "    'lat': lat_flat,\n",
    "    'lon': lon_flat,\n",
    "    'snow_depth': snow_flat\n",
    "}, geometry=[Point(lon, lat) for lon, lat in zip(lon_flat, lat_flat)], crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your lat/lon pairs from earlier\n",
    "gdf_targets = gpd.GeoDataFrame(\n",
    "    coords_df,\n",
    "    geometry=gpd.points_from_xy(coords_df['lon'], coords_df['lat']),\n",
    "    crs='EPSG:4326'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject both to UTM 33N\n",
    "real_ds_proj = gdf_real.to_crs(\"EPSG:32633\")\n",
    "gdf_targets_proj = gdf_targets.to_crs(\"EPSG:32633\")\n",
    "\n",
    "# Now perform nearest join\n",
    "matched = gpd.sjoin_nearest(gdf_targets_proj, real_ds_proj, how=\"left\", distance_col=\"distance_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Flatten real_ds lat/lon\n",
    "lat2d = real_ds['lat'].values\n",
    "lon2d = real_ds['lon'].values\n",
    "flat_coords = np.column_stack([lat2d.ravel(), lon2d.ravel()])\n",
    "\n",
    "# 2. Build KDTree\n",
    "tree = cKDTree(flat_coords)\n",
    "\n",
    "# 3. Get unique CERRA coordinates\n",
    "cerra_coords = cerra_df[['latitude', 'longitude']].drop_duplicates().values\n",
    "\n",
    "# 4. Query nearest match\n",
    "distances, flat_indices = tree.query(cerra_coords)\n",
    "y_idx, x_idx = np.unravel_index(flat_indices, lat2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerra_to_grid_map = pd.DataFrame({\n",
    "    'unit': np.arange(len(cerra_coords)),\n",
    "    'cerra_lat': cerra_coords[:, 0],\n",
    "    'cerra_lon': cerra_coords[:, 1],\n",
    "    'grid_y': y_idx,\n",
    "    'grid_x': x_idx,\n",
    "    'real_lat': lat2d[y_idx, x_idx],\n",
    "    'real_lon': lon2d[y_idx, x_idx],\n",
    "    'distance_deg': distances\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = real_ds['time'].values\n",
    "snow = real_ds['snow_depth']\n",
    "\n",
    "records = []\n",
    "\n",
    "for unit, y, x in zip(cerra_to_grid_map['unit'], y_idx, x_idx):\n",
    "    ts = snow[:, y, x].values  # shape: (time,)\n",
    "    for t, sde in zip(time, ts):\n",
    "        records.append({\n",
    "            'time': t,\n",
    "            'unit': unit,\n",
    "            'sde': sde\n",
    "        })\n",
    "\n",
    "real_df = pd.DataFrame(records)\n",
    "\n",
    "real_df['real_sde'] = real_df['real_sde']/100\n",
    "real_df.to_csv(\"real_snow_depth_ordered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Real, Statkraft and CERRA dataframes and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to have units as columns\n",
    "real_df = pd.read_csv(\"real_snow_depth_ordered.csv\")\n",
    "real_df['time'] = pd.to_datetime(real_df['time'])\n",
    "pivot_real = real_df.pivot_table(index='time', columns='unit', values='real_sde')\n",
    "pivot_real = pivot_real[pivot_real.index <= \"2020-03-01\"]\n",
    "\n",
    "statkraft_df = pd.read_csv(\"statkraft_snow_depth_ordered.csv\")\n",
    "statkraft_df['time'] = pd.to_datetime(statkraft_df['time'])\n",
    "cerra_df['time'] = pd.to_datetime(cerra_df['time'])\n",
    "# Pivot the DataFrame to have units as columns\n",
    "pivot_cerra = cerra_df.pivot_table(index='time', columns='unit', values='cerra_sde')\n",
    "# Pivot the DataFrame to have units as columns\n",
    "pivot_statkraft = statkraft_df.pivot_table(index='time', columns='unit', values='statkraft_sde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series for each unit with subplots\n",
    "fig, axes = plt.subplots(nrows=len(pivot_cerra.columns), \n",
    "                         ncols=1, \n",
    "                         sharex=True, \n",
    "                         figsize=(15, 2 * len(pivot_cerra.columns)))\n",
    "\n",
    "for i, unit in enumerate(pivot_cerra.columns):\n",
    "    ax = axes[i]\n",
    "    pivot_cerra[unit].plot(ax=ax, label='CERRA', color='green')\n",
    "    pivot_statkraft[unit].plot(ax=ax, label='Statkraft', color='orange')\n",
    "    pivot_real[unit].plot(ax=ax, label='real', color='blue')\n",
    "    \n",
    "    ax.set_title(f'Unit {unit}')\n",
    "    ax.legend()\n",
    "\n",
    "# Set the x-axis label for the last subplot\n",
    "axes[-1].set_xlabel('Time')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statkraft_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
